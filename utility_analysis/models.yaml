# ------------------------------
# OpenAI
# ------------------------------
gpt-35-turbo:
  model_name: "gpt-3.5-turbo"
  model_type: openai

gpt-4o-mini:
  model_name: "gpt-4o-mini"
  model_type: openai

gpt-4o:
  model_name: "gpt-4o"
  model_type: openai


# ------------------------------
# Anthropic
# ------------------------------
claude-3-5-sonnet:
  model_name: "claude-3-5-sonnet-20240620"
  model_type: anthropic


# ------------------------------
# xAI
# ------------------------------
grok-2-1212:
  model_name: "xai/grok-2-1212"
  model_type: xai


# ------------------------------
# Meta Llama
# ------------------------------
llama-2-7b:
  model_name: "meta-llama/Llama-2-7B-hf"
  model_type: vllm_base_model
  path: "/data/huggingface/models--meta-llama--Llama-2-7b-hf/snapshots/01c7f73d771dfac7d292323805ebc428287df4f9"
  gpu_count: 1

llama-2-7b-instruct:
  model_name: "meta-llama/Llama-2-7B-Chat-hf"
  model_type: vllm
  path: "/data/huggingface/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590"
  gpu_count: 1

llama-2-13b:
  model_name: "meta-llama/Llama-2-13B-hf"
  model_type: vllm_base_model
  path: "/data/huggingface/models--meta-llama--Llama-2-13b-hf/snapshots/5c31dfb671ce7cfe2d7bb7c04375e44c55e815b1"
  gpu_count: 1

llama-2-13b-instruct:
  model_name: "meta-llama/Llama-2-13B-Chat-hf"
  model_type: vllm
  path: "/data/huggingface/models--meta-llama--Llama-2-13b-chat-hf/snapshots/a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8"
  gpu_count: 1

llama-2-70b:
  model_name: "meta-llama/Llama-2-70B-hf"
  model_type: vllm_base_model
  path: "/data/huggingface/models--meta-llama--Llama-2-70b-hf/snapshots/3aba440b59558f995867ba6e1f58f21d0336b5bb"
  gpu_count: 1

llama-2-70b-instruct:
  model_name: "meta-llama/Llama-2-70B-Chat-hf"
  model_type: vllm
  path: "/data/huggingface/models--meta-llama--Llama-2-70b-chat-hf/snapshots/e9149a12809580e8602995856f8098ce973d1080"
  gpu_count: 1

llama-32-1b:
  model_name: "meta-llama/Llama-3.2-1B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--meta-llama--Llama-3.2-1B/snapshots/4e20de362430cd3b72f300e6b0f18e50e7166e08"
  gpu_count: 1

llama-32-1b-instruct:
  model_name: "meta-llama/Llama-3.2-1B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6"
  gpu_count: 1

llama-32-3b:
  model_name: "meta-llama/Llama-3.2-3B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062"
  gpu_count: 1

llama-32-3b-instruct:
  model_name: "meta-llama/Llama-3.2-3B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--meta-llama--Llama-3.2-3B-Instruct/snapshots/0cb88a4f764b7a12671c53f0838cd831a0843b95"
  gpu_count: 1

llama-31-8b:
  model_name: "meta-llama/Llama-3.1-8B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--meta-llama--Meta-Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b"
  gpu_count: 1

llama-31-8b-instruct:
  model_name: "meta-llama/Llama-3.1-8B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659"
  gpu_count: 1

llama-31-70b:
  model_name: "meta-llama/Llama-3.1-70B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--meta-llama--Meta-Llama-3.1-70B/snapshots/349b2ddb53ce8f2849a6c168a81980ab25258dac"
  gpu_count: 8

llama-31-70b-instruct:
  model_name: "meta-llama/Llama-3.1-70B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--meta-llama--Meta-Llama-3.1-70B-Instruct/snapshots/945c8663693130f8be2ee66210e062158b2a9693"
  gpu_count: 8

llama-33-70b-instruct:
  model_name: "meta-llama/Llama-3.3-70B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--meta-llama--Llama-3.3-70B-Instruct/snapshots/6f6073b423013f6a7d4d9f39144961bfbfbc386b"
  gpu_count: 8

llama-31-405b-fp8:
  model_name: "meta-llama/Llama-3.1-405B-FP8"
  model_type: vllm_base_model
  path: "/data/huggingface/models--meta-llama--Meta-Llama-3.1-405B-FP8/snapshots/cdb12121c5538bc05e1982ffb7105951a2daae02"
  gpu_count: 8

llama-31-405b-instruct-fp8:
  model_name: "meta-llama/Llama-3.1-405B-Instruct-FP8"
  model_type: vllm
  path: "/data/huggingface/models--meta-llama--Meta-Llama-3.1-405B-Instruct-FP8/snapshots/64a54b704768dfd589a3e4ac05d546052f67f4fd"
  gpu_count: 8

# ------------------------------
# Qwen 1.5
# ------------------------------
qwen15-05b:
  model_name: "Qwen/Qwen1.5-0.5B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen1.5-0.5B/snapshots/8f445e3628f3500ee69f24e1303c9f10f5342a39"
  gpu_count: 1

qwen15-05b-instruct:
  model_name: "Qwen/Qwen1.5-0.5B-Chat"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen1.5-0.5B-Chat/snapshots/4d14e384a4b037942bb3f3016665157c8bcb70ea"
  gpu_count: 1

qwen15-18b:
  model_name: "Qwen/Qwen1.5-1.8B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen1.5-1.8B/snapshots/7846de7ed421727b318d6605a0bfab659da2c067"
  gpu_count: 1

qwen15-18b-instruct:
  model_name: "Qwen/Qwen1.5-1.8B-Chat"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen1.5-1.8B-Chat/snapshots/e482ee3f73c375a627a16fdf66fd0c8279743ca6"
  gpu_count: 1

qwen15-4b:
  model_name: "Qwen/Qwen1.5-4B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen1.5-4B/snapshots/a66363a0c24e2155c561e4b53c658b1d3965474e"
  gpu_count: 1

qwen15-4b-instruct:
  model_name: "Qwen/Qwen1.5-4B-Chat"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen1.5-4B-Chat/snapshots/a7a4d4945d28bac955554c9abd2f74a71ebbf22f"
  gpu_count: 1

qwen15-7b:
  model_name: "Qwen/Qwen1.5-7B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen1.5-7B/snapshots/831096e3a59a0789a541415da25ef195ceb802fe"
  gpu_count: 1

qwen15-7b-instruct:
  model_name: "Qwen/Qwen1.5-7B-Chat"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen1.5-7B-Chat/snapshots/5f4f5e69ac7f1d508f8369e977de208b4803444b"
  gpu_count: 1

qwen15-14b:
  model_name: "Qwen/Qwen1.5-14B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen1.5-14B/snapshots/dce4b190d34470818e5bec2a92cb8233aaa02ca2"
  gpu_count: 2

qwen15-14b-instruct:
  model_name: "Qwen/Qwen1.5-14B-Chat"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen1.5-14B-Chat/snapshots/9492b22871f43e975435455f5c616c77fe7a50ec"
  gpu_count: 2

qwen15-32b:
  model_name: "Qwen/Qwen1.5-32B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen1.5-32B/snapshots/cefef80dc06a65f89d1d71d0adbc56d335ca2490"
  gpu_count: 8

qwen15-32b-instruct:
  model_name: "Qwen/Qwen1.5-32B-Chat"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen1.5-32B-Chat/snapshots/0997b012af6ddd5465d40465a8415535b2f06cfc"
  gpu_count: 8

qwen15-72b:
  model_name: "Qwen/Qwen1.5-72B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen1.5-72B/snapshots/93bac0d1ae83d50c43b1793e2d74a00dc43a4c36"
  gpu_count: 8

qwen15-72b-instruct:
  model_name: "Qwen/Qwen1.5-72B-Chat"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen1.5-72B-Chat/snapshots/a9435b56d61aa68714fd7b83d6cc3e698a42c8ba"
  gpu_count: 8

qwen15-110b:
  model_name: "Qwen/Qwen1.5-110B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen1.5-110B/snapshots/16659038ecdcc771c1293cf47020fa7cc2750ee8"
  gpu_count: 8

qwen15-110b-instruct:
  model_name: "Qwen/Qwen1.5-110B-Chat"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen1.5-110B-Chat/snapshots/85f86cec25901f2dbd870a86e06756903c9a876a"
  gpu_count: 8


# ------------------------------
# Qwen 2.5
# ------------------------------
qwen25-05b:
  model_name: "Qwen/Qwen2.5-0.5B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987"
  gpu_count: 1

qwen25-05b-instruct:
  model_name: "Qwen/Qwen2.5-0.5B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775"
  gpu_count: 1

qwen25-15b:
  model_name: "Qwen/Qwen2.5-1.5B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323"
  gpu_count: 1

qwen25-15b-instruct:
  model_name: "Qwen/Qwen2.5-1.5B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306"
  gpu_count: 1

qwen25-3b:
  model_name: "Qwen/Qwen2.5-3B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b"
  gpu_count: 1

qwen25-3b-instruct:
  model_name: "Qwen/Qwen2.5-3B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1"
  gpu_count: 1

qwen25-7b:
  model_name: "Qwen/Qwen2.5-7B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen2.5-7B/snapshots/d149729398750b98c0af14eb82c78cfe92750796"
  gpu_count: 1

qwen25-7b-instruct:
  model_name: "Qwen/Qwen2.5-7B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen2.5-7B-Instruct/snapshots/bb46c15ee4bb56c5b63245ef50fd7637234d6f75"
  gpu_count: 1

qwen25-14b:
  model_name: "Qwen/Qwen2.5-14B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen2.5-14B/snapshots/97e1e76335b7017d8f67c08a19d103c0504298c9"
  gpu_count: 2

qwen25-14b-instruct:
  model_name: "Qwen/Qwen2.5-14B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen2.5-14B-Instruct/snapshots/cf98f3b3bbb457ad9e2bb7baf9a0125b6b88caa8"
  gpu_count: 2

qwen25-32b:
  model_name: "Qwen/Qwen2.5-32B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen2.5-32B/snapshots/1818d35814b8319459f4bd55ed1ac8709630f003"
  gpu_count: 8

qwen25-32b-instruct:
  model_name: "Qwen/Qwen2.5-32B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen2.5-32B-Instruct/snapshots/5ede1c97bbab6ce5cda5812749b4c0bdf79b18dd"
  gpu_count: 8

qwq-32b-preview:
  model_name: "Qwen/QwQ-32B-Preview"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--QwQ-32B-Preview/snapshots/1032e81cb936c486aae1d33da75b2fbcd5deed4a"
  gpu_count: 8

qwen25-72b:
  model_name: "Qwen/Qwen2.5-72B"
  model_type: vllm_base_model
  path: "/data/huggingface/models--Qwen--Qwen2.5-72B/snapshots/efba10c8e54e91e0d9570ab5f7b51a958474d4cb"
  gpu_count: 8

qwen25-72b-instruct:
  model_name: "Qwen/Qwen2.5-72B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen2.5-72B-Instruct/snapshots/d3d951150c1e5848237cd6a7ad11df4836aee842"
  gpu_count: 8

qwen25-vl-7b-instruct:
  model_name: "Qwen/Qwen2.5-VL-7B-Instruct"
  model_type: vllm
  path: "Qwen/Qwen2.5-VL-7B-Instruct"
  gpu_count: 1

qwen25-vl-32b-instruct:
  model_name: "Qwen/Qwen2.5-VL-32B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--Qwen--Qwen2.5-VL-32B-Instruct/snapshots/7cfb30d71a1f4f49a57592323337a4a4727301da"
  gpu_count: 1

qwen25-vl-72b-instruct:
  model_name: "Qwen/Qwen2.5-VL-72B-Instruct"
  model_type: vllm
  path: "/data/huggingface/Qwen/Qwen2.5-VL-72B-Instruct"
  gpu_count: 1

internvl3-38b-instruct:
  model_name: "OpenGVLab/InternVL3-38B"
  model_type: vllm
  path: "/data/huggingface/models--OpenGVLab--InternVL3-38B-Instruct/snapshots/81c9a040f587e63dc46f128efac04e3f86952847"
  gpu_count: 1

# ------------------------------
# Google Gemma
# ------------------------------
gemma-2-2b:
  model_name: "google/gemma-2-2b"
  model_type: vllm_base_model
  path: "/data/huggingface/models--google--gemma-2-2b/snapshots/c5ebcd40d208330abc697524c919956e692655cf"
  gpu_count: 1
  accepts_system_message: False

gemma-2-2b-it:
  model_name: "google/gemma-2-2b-it"
  model_type: vllm
  path: "/data/huggingface/models--google--gemma-2-2b-it/snapshots/299a8560bedf22ed1c72a8a11e7dce4a7f9f51f8"
  gpu_count: 1
  accepts_system_message: False

gemma-2-9b:
  model_name: "google/gemma-2-9b"
  model_type: vllm_base_model
  path: "/data/huggingface/models--google--gemma-2-9b/snapshots/33c193028431c2fde6c6e51f29e6f17b60cbfac6"
  gpu_count: 4
  accepts_system_message: False

gemma-2-9b-it:
  model_name: "google/gemma-2-9b-it"
  model_type: vllm
  path: "/data/huggingface/models--google--gemma-2-9b-it/snapshots/11c9b309abf73637e4b6f9a3fa1e92e615547819"
  gpu_count: 4
  accepts_system_message: False

gemma-2-27b:
  model_name: "google/gemma-2-27b"
  model_type: vllm_base_model
  path: "/data/huggingface/models--google--gemma-2-27b/snapshots/938270f5272feb02779b55c2bb2fffdd0f53ff0c"
  gpu_count: 4
  accepts_system_message: False

gemma-2-27b-it:
  model_name: "google/gemma-2-27b-it"
  model_type: vllm
  path: "/data/huggingface/models--google--gemma-2-27b-it/snapshots/aaf20e6b9f4c0fcf043f6fb2a2068419086d77b0"
  gpu_count: 4
  accepts_system_message: False

gemma-3-27b-it:
  model_name: "google/gemma-3-27b-it"
  model_type: vllm
  path: "/data/huggingface/models--google--gemma-3-27b-it/snapshots/005ad3404e59d6023443cb575daa05336842228a"
  gpu_count: 4
  accepts_system_message: False

# ------------------------------
# AllenAI OLMo
# ------------------------------
olmo-7b:
  model_name: "allenai/OLMo-7B"
  model_type: vllm
  path: "/data/huggingface/models--allenai--OLMo-7B/snapshots/46fba0de8af86b2eb5329fb11a2994e7c0df3eb9"
  gpu_count: 4

olmo-2-1124-7b-instruct:
  model_name: "allenai/OLMo-2-1124-7B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--allenai--OLMo-2-1124-7B-Instruct/snapshots/470b1fba1ae01581f270116362ee4aa1b97f4c84"
  gpu_count: 4

olmo-2-1124-13b-instruct:
  model_name: "allenai/OLMo-2-1124-13B-Instruct"
  model_type: vllm
  path: "/data/huggingface/models--allenai--OLMo-2-1124-13B-Instruct/snapshots/3a5c85baefbb1896a54d56fe2e76c0395627ddf4"
  gpu_count: 4
